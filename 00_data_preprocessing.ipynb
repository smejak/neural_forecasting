{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584124c4-f063-4ef4-a73b-190e4cca8e96",
   "metadata": {},
   "source": [
    "# Neural Traces Data Preprocessing Pipeline\n",
    "\n",
    "Goals:\n",
    "\n",
    "* HMM & RNN - compatible data format (# neurons, traces in timeframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea11ea99-6323-4bf2-b414-eaad59cbf209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d765ee8-64d5-4547-a528-94efed2428d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./data/leah_20200206_07_08_09_10_11_12_13.pickle', 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db8065-b971-4076-a9c2-ea43db137657",
   "metadata": {},
   "source": [
    "The data has the following structure:\n",
    "\n",
    "- all_data:\n",
    "  - was_completed\n",
    "  - was_correct\n",
    "  - stim_dir\n",
    "  - correct_side\n",
    "  - response_side\n",
    "  - prior\n",
    "  - noise\n",
    "  - traces\n",
    "  - task_info\n",
    "  - frame_info\n",
    "\n",
    "- completed_trials_data:\n",
    "  - was_completed\n",
    "  - was_correct\n",
    "  - stim_dir\n",
    "  - correct_side\n",
    "  - prior\n",
    "  - noise\n",
    "  - response_side\n",
    "  - traces_stim_aligned\n",
    "  - traces_resp_aligned\n",
    "  - completed_inds\n",
    "  - frame_info\n",
    "  \n",
    "It doesn't make sense to look at all_data, let's just do `completed_trials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986df9a5-a529-4879-a176-0a63facda966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i]['completed_trials_data']['traces'] = data[i]['all_data']['traces']\n",
    "    data[i] = data[i]['completed_trials_data']\n",
    "    del data[i]['was_completed'] # we know it's completed (I also checked before)\n",
    "    del data[i]['correct_side'] # same as stim_dir\n",
    "    del data[i]['traces_resp_aligned']\n",
    "    del data[i]['traces_stim_aligned']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd90b14-9d4a-4564-b5d3-ab1f09dc1fe3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b8b870-4c2f-44bc-b6a8-346b9f870e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates the u_in object (8, # timeframes)\n",
    "def process_stim_trials(stim_trials, u_in, start_frames, end_frames, stim_dict, no_stims):\n",
    "    issues_detected = []\n",
    "\n",
    "    for i, stimulus in enumerate(stim_trials):\n",
    "        stim_vector = np.zeros(no_stims)\n",
    "        stim_vector[stim_dict[stimulus]] = 1\n",
    "        \n",
    "        start_frame = int(start_frames[i])\n",
    "        end_frame = int(end_frames[i])\n",
    "\n",
    "        # Check for mismatched start and end frames\n",
    "        if start_frame == end_frame:\n",
    "            issues_detected.append(f\"Issue at index {i}: Start frame is the same as end frame ({start_frame}).\")\n",
    "            continue  # Skip this iteration\n",
    "\n",
    "        # Ensure correct ordering of frames\n",
    "        if start_frame > end_frame:\n",
    "            issues_detected.append(f\"Issue at index {i}: Start frame ({start_frame}) is greater than end frame ({end_frame}).\")\n",
    "            continue  # Skip this iteration\n",
    "\n",
    "        stim_length = end_frame - start_frame\n",
    "\n",
    "        # Attempt to assign the values\n",
    "        try:\n",
    "            u_in[:, start_frame:end_frame] = np.tile(stim_vector[:, np.newaxis], (1, stim_length))\n",
    "        except ValueError as ve:\n",
    "            issues_detected.append(f\"Issue at index {i}: {ve}\")\n",
    "\n",
    "    return issues_detected, u_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7c3c02-241a-494c-97e5-7851c0be14d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (8, 35745)\n",
      "Input shape: (8, 20905)\n",
      "Input shape: (8, 37961)\n",
      "Input shape: (8, 37717)\n",
      "Input shape: (8, 37717)\n",
      "Input shape: (8, 32876)\n",
      "Input shape: (8, 35225)\n"
     ]
    }
   ],
   "source": [
    "stim_dict = { # this will be used for the one-hot encoding\n",
    "    -1.0: 0, \n",
    "    -0.75: 1, \n",
    "    -0.5: 2, \n",
    "    -0.25: 3, \n",
    "    0.25: 4, \n",
    "    0.5: 5, \n",
    "    0.75: 6, \n",
    "    1.0: 7}\n",
    "\n",
    "no_stims = 8\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # transform left and right into -1 and 1\n",
    "    stim_dir = data[i]['stim_dir']\n",
    "    stim_dir = np.array([-1 if drn == 'left' else 1 for drn in stim_dir])\n",
    "    stim_trial = np.empty(data[i]['noise'].shape)\n",
    "    stim_trial = stim_dir * data[i]['noise'] # this captures both the direction and the noise level\n",
    "\n",
    "    len_neural_traces = data[i]['traces'].shape[1]\n",
    "    u_in = np.zeros((no_stims, len_neural_traces))\n",
    "    print(f'Input shape: {u_in.shape}')\n",
    "    \n",
    "    start_frames = data[i]['frame_info']['stim_start_frame']\n",
    "    end_frames = data[i]['frame_info']['stim_end_frame']\n",
    "    issues, u_in = process_stim_trials(stim_trial, u_in, start_frames, end_frames, stim_dict, no_stims)\n",
    "    data[i]['u_in'] = u_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e954ba-1ccd-4fff-a33c-a0f3a064ff6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Just trials\n",
    "\n",
    "Take the `stim_start_frame` and the `response_frame` (+20 timeframes for the reward and end of trial), adjust `traces` and `u_in`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b577dddb-6744-4567-887c-04ba312135fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(len(data)):\n",
    "\n",
    "    trial_traces = None\n",
    "    trial_inputs = None\n",
    "    s = data[idx]['frame_info']['stim_start_frame']\n",
    "    e = data[idx]['frame_info']['response_frame'] + 20\n",
    "\n",
    "    for start, end in zip(s, e):\n",
    "        if (trial_traces is None) and (trial_inputs is None):\n",
    "            trial_traces = data[idx]['traces'][:, int(start): int(end)]\n",
    "            trial_inputs = data[idx]['u_in'][:, int(start): int(end)]\n",
    "        else:\n",
    "            t = data[idx]['traces'][:, int(start): int(end)]\n",
    "            i = data[idx]['u_in'][:, int(start): int(end)]\n",
    "            trial_traces = np.concatenate((trial_traces, t), axis=1)\n",
    "            trial_inputs = np.concatenate((trial_inputs, i), axis=1)\n",
    "\n",
    "    data[idx]['trial_traces'] = trial_traces\n",
    "    data[idx]['trial_u_in'] = trial_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb8333-c453-45c7-84c2-4a4689e1d32d",
   "metadata": {},
   "source": [
    "## Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eaaf768-c930-4b3e-9493-b32b0b26a0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./data/preprocessed_data.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b12e5-fa5e-4f01-9082-70aa12b22aed",
   "metadata": {},
   "source": [
    "## Optional adjustments\n",
    "\n",
    "Further preprocessing: \n",
    "\n",
    "* Gaussian smoothing\n",
    "* normalization with max and mean\n",
    "\n",
    "Note: this will be done just before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8476dd-cbd3-433b-8b50-ad5d4097d5af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1ddeb6-55e7-470e-889a-9dd702070ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIGMA = 10 # needs to be experimented with\n",
    "\n",
    "# for CORNN, you need two sets of traces, off-set by 1 timeframe (inputs and targets)\n",
    "traces_raw = data[0]['traces']\n",
    "traces_raw = traces_raw / np.max(traces_raw,axis = 1)[:,None]\n",
    "traces_raw = traces_raw - np.mean(traces_raw,axis = 1)[:,None]\n",
    "\n",
    "traces_raw2 = data[0]['traces']\n",
    "traces_raw2 = traces_raw2 / np.max(traces_raw2,axis = 1)[:,None]\n",
    "traces_raw2 = traces_raw2 - np.mean(traces_raw2,axis = 1)[:,None]\n",
    "\n",
    "r_in = gaussian_filter1d(traces_raw, sigma=SIGMA) # just so that CORNN targets are offset by 1\n",
    "r_tar = gaussian_filter1d(traces_raw2, sigma=SIGMA)\n",
    "\n",
    "u_in = gaussian_filter1d(data[0]['u_in'], sigma=SIGMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b27e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_traces(traces):\n",
    "    \"\"\"\n",
    "    Normalize neural traces values to lie between -1 and 1.\n",
    "    \"\"\"\n",
    "    t = traces / np.max(traces, axis = 1)[:,None]\n",
    "    t = t - np.mean(t, axis = 1)[:,None]\n",
    "    return t\n",
    "\n",
    "def full_data_prep(traces_raw, traces_raw_offset, u_in_raw, SIGMA, ds_rate):\n",
    "    t_raw = normalize_traces(traces_raw)\n",
    "    t_raw_offset = normalize_traces(traces_raw_offset)\n",
    "        \n",
    "    r_in = gaussian_filter1d(t_raw, axis=1, sigma=SIGMA)\n",
    "    r_tar = gaussian_filter1d(t_raw_offset, axis=1, sigma=SIGMA)\n",
    "\n",
    "    u_in = gaussian_filter1d(u_in_raw, sigma=SIGMA)\n",
    "\n",
    "    r_in = block_reduce(r_in, block_size=(1, ds_rate), func=np.mean, cval=np.mean(r_in))\n",
    "    r_tar = block_reduce(r_tar, block_size=(1, ds_rate), func=np.mean, cval=np.mean(r_tar))\n",
    "    u_in = block_reduce(u_in, block_size=(1, ds_rate), func=np.mean, cval=np.mean(u_in))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
